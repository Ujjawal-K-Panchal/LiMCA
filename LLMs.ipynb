{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9c2870-1e84-4382-b28a-2c6d2321a6d5",
   "metadata": {},
   "source": [
    "# LLM File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e90710-65c1-42ee-a2a5-1f9b021254fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.38.0.dev0\n",
      "Uninstalling transformers-4.38.0.dev0:\n",
      "  Successfully uninstalled transformers-4.38.0.dev0\n",
      "Found existing installation: accelerate 0.28.0.dev0\n",
      "Uninstalling accelerate-0.28.0.dev0:\n",
      "  Successfully uninstalled accelerate-0.28.0.dev0\n",
      "Found existing installation: peft 0.8.2\n",
      "Uninstalling peft-0.8.2:\n",
      "  Successfully uninstalled peft-0.8.2\n",
      "Found existing installation: bitsandbytes 0.42.0\n",
      "Uninstalling bitsandbytes-0.42.0:\n",
      "  Successfully uninstalled bitsandbytes-0.42.0\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in ./venv4limca/lib/python3.10/site-packages (from bitsandbytes) (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in ./venv4limca/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.26.4)\n",
      "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-_34rtqiq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-_34rtqiq\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 2f1003be86f11c8d97d7c2e6a7739dbb6fa795f2\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv4limca/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv4limca/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv4limca/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv4limca/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv4limca/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (2024.2.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8505457 sha256=44971a19c3816a19c484ae8c266a1bb3b7d9b779ebd073a3bc328e2a7d4ea1d6\n",
      "  Stored in directory: /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-ephem-wheel-cache-l9dhy3ru/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.38.0.dev0\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-pa7zxyk1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-pa7zxyk1\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 8db74d42c41d7d8bbebd5afc60b97f5ac9508b9f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (23.2)\n",
      "Requirement already satisfied: psutil in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (2.2.0)\n",
      "Requirement already satisfied: transformers in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (4.38.0.dev0)\n",
      "Requirement already satisfied: tqdm in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (4.66.2)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.8.2)\n",
      "  Using cached accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: safetensors in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./venv4limca/lib/python3.10/site-packages (from peft==0.8.2) (0.20.3)\n",
      "Requirement already satisfied: filelock in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2024.2.0)\n",
      "Requirement already satisfied: requests in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./venv4limca/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv4limca/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv4limca/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv4limca/lib/python3.10/site-packages (from transformers->peft==0.8.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv4limca/lib/python3.10/site-packages (from transformers->peft==0.8.2) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv4limca/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.8.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv4limca/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.8.2) (1.3.0)\n",
      "Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.8.2-py3-none-any.whl size=184047 sha256=96d714671b322379bb2adf1d19adc6bed711b16ed86244530ec1dcd4170721ed\n",
      "  Stored in directory: /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-ephem-wheel-cache-onqe2ffi/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
      "Successfully built peft\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-0.27.2 peft-0.8.2\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-_ldqmi2p\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-req-build-_ldqmi2p\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 97d2168e5953fe7373a06c69c02c5a00a84d5344\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (23.2)\n",
      "Requirement already satisfied: psutil in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv4limca/lib/python3.10/site-packages (from accelerate==0.28.0.dev0) (0.4.2)\n",
      "Requirement already satisfied: filelock in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./venv4limca/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: requests in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.28.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv4limca/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.28.0.dev0) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv4limca/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv4limca/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0.dev0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv4limca/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.28.0.dev0) (1.3.0)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.28.0.dev0-py3-none-any.whl size=282549 sha256=38fbe1e5b81c3c126cb8fe9298a95b194c5be34c33dd80d6d29de45e6cd5615e\n",
      "  Stored in directory: /private/var/folders/9m/2gkxssts383c3zjdqfnrzwcr0000gn/T/pip-ephem-wheel-cache-1r1nk7gl/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "Successfully installed accelerate-0.28.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip uninstall -y accelerate\n",
    "!pip uninstall -y peft\n",
    "!pip uninstall -y bitsandbytes\n",
    "\n",
    "!pip install bitsandbytes\n",
    "!pip install git+https://github.com/huggingface/transformers.git \n",
    "!pip install git+https://github.com/huggingface/peft.git\n",
    "!pip install git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "598afa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, transformers, peft, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbb779b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = \"mac\" #\"colab\"\n",
    "llmname = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "device = \"cuda:0\" if platform == \"colab\" else \"mps:0\"\n",
    "modelstore = \"./models\"\n",
    "max_seq_len = 4096\n",
    "alpha = 16\n",
    "rank = 8\n",
    "if not os.path.exists(modelstore):\n",
    "    os.makedirs(modelstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a05e6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "     return \"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\"\n",
    "\n",
    "def get_tokenizer(name: str = llmname, model_max_length: int = max_seq_len):\n",
    "\ttok = transformers.AutoTokenizer.from_pretrained(\n",
    "\t\tname,\n",
    "\t\tcache_dir = modelstore,\n",
    "\t\tmodel_max_length = model_max_length,\n",
    "\t\ttoken = get_token()\n",
    "\t)\n",
    "\ttok.padding_side = 'right'\n",
    "\ttok.model_max_length = max_seq_len\n",
    "\treturn tok\n",
    "\n",
    "def get_model(name: str = llmname, quantize: bool | str = \"qlora\"):\n",
    "    if isinstance(quantize, bool):\n",
    "        model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            name,\n",
    "            cache_dir = modelstore,\n",
    "            token = get_token()\n",
    "        )\n",
    "    if quantize == True:\n",
    "        model = model.to(torch.float16)\n",
    "    elif quantize == \"qlora\":\n",
    "        nf4_config = transformers.BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype = torch.float16,\n",
    "            )\n",
    "        lora_config = peft.LoraConfig(\n",
    "                r = rank,\n",
    "                lora_alpha = alpha,\n",
    "                target_modules = [\"q_proj\", \"v_proj\"],\n",
    "                bias = \"none\",\n",
    "                task_type = \"CAUSAL_LM\",\n",
    "            )\n",
    "        model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            name,\n",
    "            cache_dir = modelstore,\n",
    "            quantization_config = nf4_config,\n",
    "            token = get_token(),\n",
    "        )\n",
    "        model = peft.get_peft_model(model, lora_config)\n",
    "        model = model.to(device) #replace w. CUDA:0 for non-MAC.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b198eba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tok \u001b[38;5;241m=\u001b[39m get_tokenizer()\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 38\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(name, quantize)\u001b[0m\n\u001b[1;32m     25\u001b[0m nf4_config \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mBitsAndBytesConfig(\n\u001b[1;32m     26\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m     bnb_4bit_compute_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m peft\u001b[38;5;241m.\u001b[39mLoraConfig(\n\u001b[1;32m     32\u001b[0m         r \u001b[38;5;241m=\u001b[39m rank,\n\u001b[1;32m     33\u001b[0m         lora_alpha \u001b[38;5;241m=\u001b[39m alpha,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m         task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     )\n\u001b[0;32m---> 38\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodelstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnf4_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m peft\u001b[38;5;241m.\u001b[39mget_peft_model(model, lora_config)\n\u001b[1;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#replace w. CUDA:0 for non-MAC.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/College/ms/ECS260/LiMCA/venv4limca/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/College/ms/ECS260/LiMCA/venv4limca/lib/python3.10/site-packages/transformers/modeling_utils.py:3024\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3027\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[1;32m   3028\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/Desktop/College/ms/ECS260/LiMCA/venv4limca/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:62\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
     ]
    }
   ],
   "source": [
    "tok = get_tokenizer()\n",
    "model = get_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
